{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 识别出DSB3数据集中的肺结节\n",
    "\n",
    "## 步骤\n",
    "* 加载和处理数据集\n",
    "* 使用训练好的U-net生成掩模\n",
    "* 使用训练好的CNN降低假阳性率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 程序执行前设置 ###\n",
    "\n",
    "unetweightspath=\"modelpths/unet9.pth\"                   # UNet模型权重路径\n",
    "truenoduleweightspath=\"modelpths/truenodule-cnn.pth\"    # 用于判断是否是真结节的CNN模型权重路径\n",
    "INPUT_FOLDER = 'F:/Datasets/DSB3/stage1/'               # DSB3数据集路径\n",
    "datafolder=\"F:/Datasets/DSB3-processed/\"                # 处理后的数据保存路径\n",
    "# 程序会自动创建该文件夹及其子文件夹images和masks\n",
    "\n",
    "import os\n",
    "os.makedirs(datafolder + 'images', exist_ok=True)\n",
    "os.makedirs(datafolder + 'masks', exist_ok=True)\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "# 尝试使用可扩展的内存段来避免CUDA内存碎片化\n",
    "# 请注意，这可能会导致性能下降，因为这会导致更多的内存分配和释放操作\n",
    "\n",
    "######################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import label\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "import torch\n",
    "\n",
    "# 使用cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "patients = os.listdir(INPUT_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入肺结节分割模型\n",
    "from NoduleUNet import UNet\n",
    "\n",
    "unetmodel = UNet().to(device)\n",
    "unetmodel.load_state_dict(torch.load(unetweightspath))\n",
    "unetmodel.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分类结节与非结节\n",
    "from TrueNoduleClassifier import NoduleClassifier\n",
    "\n",
    "# 创建模型实例\n",
    "Classifymodel = NoduleClassifier().to(device)\n",
    "\n",
    "# 加载训练好的模型\n",
    "Classifymodel.load_state_dict(torch.load(truenoduleweightspath))\n",
    "Classifymodel.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义一些方法\n",
    "\n",
    "from ProcessCTData import load_scan, get_pixels_hu, Standardizeimage\n",
    "\n",
    "# 从文件中处理图像\n",
    "def process_image_from_file(ppix):\n",
    "    processpix = np.ndarray([ppix.shape[0], 1, 512, 512], dtype=np.float32)\n",
    "    for i in range(ppix.shape[0]):\n",
    "        processpix[i, 0] = Standardizeimage(ppix[i])\n",
    "    return processpix\n",
    "\n",
    "# 预测图像的掩码\n",
    "def predict_mask(images):\n",
    "    num_test = images.shape[0]\n",
    "    imgs_mask_test = np.ndarray([num_test, 1, 512, 512], dtype=np.float32)\n",
    "    for i in range(num_test):\n",
    "        imgs_mask_test[i] = unetmodel.forward(torch.from_numpy(images[i:i+1]).to(device).float()).cpu().detach().numpy()[0]\n",
    "        torch.cuda.empty_cache()\n",
    "    return imgs_mask_test\n",
    "\n",
    "# 获取检测到结节的切片索引\n",
    "def get_nodule_index(imgs_mask_test):\n",
    "    mask_sum = [np.sum(maskslice[0]) for maskslice in imgs_mask_test]\n",
    "    print('mask_sum: ', mask_sum)\n",
    "    return [i for i in range(len(mask_sum)) if mask_sum[i] > 5]\n",
    "\n",
    "# 获取真正的索引\n",
    "def get_true_indices(processed_pix, nodule_index):\n",
    "    nodule_imgs = [processed_pix[ind] for ind in nodule_index]\n",
    "    nodule_imgs = np.array(nodule_imgs, np.float32)\n",
    "    print('nodule_imgs shape: ', nodule_imgs.shape)\n",
    "    outputs = Classifymodel.forward(torch.from_numpy(nodule_imgs).to(device).float())\n",
    "    del nodule_imgs\n",
    "    torch.cuda.empty_cache()\n",
    "    print('outputs: ', outputs)\n",
    "    _, predictions = torch.max(outputs, dim=1)\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()\n",
    "    print('predictions: ', predictions)\n",
    "    true_indices = [ind for i, ind in enumerate(nodule_index) if predictions[i] == 1]\n",
    "    return true_indices\n",
    "\n",
    "\n",
    "# 获取最大结节的属性\n",
    "def get_largest_nodule_properties(mask):\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask < 0.5] = 0\n",
    "    mask = mask.astype(np.int8)\n",
    "    labeled_array, nf = label(mask)\n",
    "    areas_in_slice = []\n",
    "    if nf > 1:\n",
    "        for n in range(nf):\n",
    "            lab = np.array(labeled_array)\n",
    "            lab[lab != (n + 1)] = 0\n",
    "            lab[lab == (n + 1)] = 1\n",
    "            areas_in_slice.append(np.sum(lab))\n",
    "        nlargest = areas_in_slice.index(max(areas_in_slice))\n",
    "        labeled_array[labeled_array != (nlargest + 1)] = 0\n",
    "        nodule_props = regionprops(labeled_array)\n",
    "    else:\n",
    "        nodule_props = regionprops(mask)\n",
    "    area = nodule_props[0].area\n",
    "    eccentricity = nodule_props[0].eccentricity\n",
    "    diam = nodule_props[0].equivalent_diameter\n",
    "    diammajor = nodule_props[0].major_axis_length\n",
    "    spiculation = nodule_props[0].solidity\n",
    "    return area, eccentricity, diam, diammajor, spiculation\n",
    "\n",
    "\n",
    "def process_patient(i):\n",
    "    print(\"Processing patient #\", i)\n",
    "    patient_scan = load_scan(INPUT_FOLDER + patients[i])\n",
    "    patient_pix = get_pixels_hu(patient_scan)\n",
    "    processed_pix = process_image_from_file(patient_pix)\n",
    "    processed_pix[processed_pix==-0] = 0\n",
    "    mask = predict_mask(processed_pix)\n",
    "    nodule_index = get_nodule_index(mask)\n",
    "    print(\"Nodule index: \", nodule_index)\n",
    "    if len(nodule_index) == 0:\n",
    "        return [], [], []\n",
    "    \n",
    "    true_inds = get_true_indices(processed_pix, nodule_index)\n",
    "    print(\"True indices: \", true_inds)\n",
    "    if len(true_inds) == 0:\n",
    "        return [], [], []\n",
    "    \n",
    "    nodule_images = []\n",
    "    nodule_masks = []\n",
    "    sample = []\n",
    "    area = []\n",
    "    nodule_indices = []\n",
    "\n",
    "    for ind in true_inds:\n",
    "        nodule_images.append(patient_pix[ind])\n",
    "        nodule_masks.append(mask[ind])\n",
    "        sample.append(patients[i])\n",
    "        area.append(np.sum(mask[ind]))\n",
    "        nodule_indices.append(ind)\n",
    "\n",
    "    nodule_images = np.array(nodule_images)\n",
    "    nodule_masks = np.array(nodule_masks)\n",
    "\n",
    "    np.save(datafolder + \"images/\" + \"nodule_images_\" + f\"{i:04d}\" + \".npy\", nodule_images)\n",
    "    np.save(datafolder + \"masks/\" + \"nodule_masks_\" + f\"{i:04d}\" + \".npy\", nodule_masks)\n",
    "\n",
    "    return sample, area, nodule_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(patients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 开始处理\n",
    "\n",
    "sample = []\n",
    "area = []\n",
    "nodule_indices = []\n",
    "\n",
    "from tqdm.contrib.concurrent import thread_map\n",
    "\n",
    "MAX_WORKERS = 28 # 最大线程数\n",
    "\n",
    "# 多线程处理数据\n",
    "results = thread_map(process_patient, range(len(patients)), max_workers=MAX_WORKERS)\n",
    "# results = thread_map(process_patient, selected_patients, range(len(selected_patients)), max_workers=MAX_WORKERS)\n",
    "\n",
    "for result in results:\n",
    "\n",
    "    sample.extend(result[0])\n",
    "    area.extend(result[1])\n",
    "    nodule_indices.extend(result[2])\n",
    "# 267min 11.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新读取图像\n",
    "\n",
    "LoadPath = 'F:/Datasets/DSB3-processed/'\n",
    "\n",
    "# 处理后的图像\n",
    "image_npy_paths = [\n",
    "    os.path.join(os.getcwd(), f\"{LoadPath}images\", x)\n",
    "    for x in os.listdir(f\"{LoadPath}images\")\n",
    "]\n",
    "\n",
    "# 掩模\n",
    "mask_npy_paths = [\n",
    "    os.path.join(os.getcwd(), f\"{LoadPath}masks\", x)\n",
    "    for x in os.listdir(f\"{LoadPath}masks\")\n",
    "]\n",
    "\n",
    "print(\"CT scans images: \" + str(len(image_npy_paths)))\n",
    "print(\"CT scans masks: \" + str(len(mask_npy_paths)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "\n",
    "nodule_images = []\n",
    "nodule_masks = []\n",
    "\n",
    "for i in range(len(image_npy_paths)):\n",
    "    nodule_images.append(np.load(image_npy_paths[i]))\n",
    "    nodule_masks.append(np.load(mask_npy_paths[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodule_images = np.vstack(nodule_images)\n",
    "nodule_masks = np.vstack(nodule_masks)\n",
    "\n",
    "print(\"Nodule images shape: \", nodule_images.shape)\n",
    "print(\"Nodule masks shape: \", nodule_masks.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodule_images的形状不为4维，需要添加一个维度\n",
    "\n",
    "nodule_images = nodule_images[:, np.newaxis, :, :]\n",
    "\n",
    "print(\"Nodule images shape: \", nodule_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "\n",
    "np.save(datafolder + \"DSBNoduleImages.npy\", nodule_images)\n",
    "np.save(datafolder + \"DSBNoduleMasks.npy\", nodule_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看图像与掩模\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "for i, j in enumerate((10, 22, 46, 60)):\n",
    "    ax[0, i].axis('off')\n",
    "    ax[0, i].imshow(nodule_images[j][0], cmap='gray')\n",
    "    ax[0, i].set_title(\"Nodule Image\")\n",
    "    ax[1, i].axis('off')\n",
    "    ax[1, i].imshow(nodule_masks[j][0], cmap='gray')\n",
    "    ax[1, i].set_title(\"Nodule Mask\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成特征表\n",
    "\n",
    "meannodule_HU = []\n",
    "nodule_count = []\n",
    "largest_area_list = []\n",
    "eccentricity_list = []\n",
    "diam_list = []\n",
    "diammajor_list = []\n",
    "spiculation_list = []\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(nodule_masks.shape[0])):\n",
    "    print(\"Processing nodule #\", i)\n",
    "    mask = nodule_masks[i, 0]\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask < 0.5] = 0\n",
    "    meannodule_HU.append(np.sum(nodule_images[i, 0] * mask) / np.sum(mask))\n",
    "    labeled_array, features = label(mask)\n",
    "    nodule_count.append(features)\n",
    "    area, eccentricity, diam, diammajor, spiculation = get_largest_nodule_properties(nodule_masks[i, 0])\n",
    "    largest_area_list.append(area)\n",
    "    eccentricity_list.append(eccentricity)\n",
    "    diam_list.append(diam)\n",
    "    diammajor_list.append(diammajor)\n",
    "    spiculation_list.append(spiculation)\n",
    "table = pd.DataFrame({\"Patient\": sample, \"NoduleIndex\": nodule_indices, \"Area\": area, \n",
    "                      \"MeanHU\": meannodule_HU, \"LargestNoduleArea\": largest_area_list,\n",
    "                      \"Eccentricity\": eccentricity_list, \"Diameter\": diam_list, \n",
    "                      \"DiameterMajor\": diammajor_list, \"Spiculation\": spiculation_list})\n",
    "\n",
    "table.to_csv(datafolder+\"DSBNoduleFeatures.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
