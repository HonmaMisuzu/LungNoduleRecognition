{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 训练U-net模型\n",
    "\n",
    "## 摘要\n",
    "\n",
    "* 加载CT扫描图像，去除面积小于25（即直径约小于2.5mm）的样本\n",
    "* 训练一个部分基于ResNet18预训练模型构建的U-net模型\n",
    "* 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "datafolder='processeddata'                              # 经过预处理的数据的保存位置\n",
    "weightsfolder='modelpths'                               # 模型权重保存位置\n",
    "noduleimages=np.load(datafolder+\"/noduleimages.npy\")    # 肺部图像数据\n",
    "nodulemasks=np.load(datafolder+\"/nodulemasks.npy\")      # 肺结节掩膜数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制肺结节的面积分布\n",
    "nodulesize=[np.sum(mask) for mask in nodulemasks]\n",
    "plt.hist([nod for nod in nodulesize if nod<300],bins=50)\n",
    "plt.xlabel(\"Area\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove samples with nodulesize<25, which is ~radius=2.8\n",
    "# 删除掩膜面积小于25的样本\n",
    "filteredindicies=[i for i in range(len(nodulesize)) if nodulesize[i]>25]\n",
    "noduleimages=noduleimages[filteredindicies]\n",
    "nodulemasks=nodulemasks[filteredindicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制肺结节的HU图\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(noduleimages[42])                 #显示第42张HU值图\n",
    "plt.annotate('', xy=(317, 367), xycoords='data',\n",
    "             xytext=(0.5, 0.5), textcoords='figure fraction',\n",
    "             arrowprops=dict(arrowstyle=\"->\"))\n",
    "#plt.savefig(\"images/test.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据形状与类型转换\n",
    "noduleimages=noduleimages.reshape(noduleimages.shape[0],1,512,512)\n",
    "nodulemasks=nodulemasks.reshape(nodulemasks.shape[0],1,512,512)\n",
    "noduleimages[noduleimages==-0]=0\n",
    "nodulemasks[nodulemasks<=0]=0\n",
    "nodulemasks[nodulemasks>0]=1\n",
    "imagestrain, imagestest, maskstrain, maskstest = train_test_split(noduleimages.astype(float),nodulemasks.astype(float),test_size=0.3)\n",
    "\n",
    "imagestrain=torch.from_numpy(imagestrain).float()\n",
    "maskstrain=torch.from_numpy(maskstrain).float()\n",
    "imagestest=torch.from_numpy(imagestest).float()\n",
    "maskstest=torch.from_numpy(maskstest).float()\n",
    "\n",
    "del noduleimages, nodulemasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net Model\n",
    "import torchvision\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.conv_relu = nn.Sequential(\n",
    "            nn.Conv2d(middle_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "            )\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x1 = torch.cat((x1, x2), dim=1)\n",
    "        x1 = self.conv_relu(x1)\n",
    "        return x1\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.n_class = 1\n",
    "\n",
    "        self.base_model = torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT) # or .IMAGENET1K_V1\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "            self.base_layers[1],\n",
    "            self.base_layers[2])\n",
    "        self.layer2 = nn.Sequential(*self.base_layers[3:5])\n",
    "        self.layer3 = self.base_layers[5]\n",
    "        self.layer4 = self.base_layers[6]\n",
    "        self.layer5 = self.base_layers[7]\n",
    "        self.decode4 = Decoder(512, 256+256, 256)\n",
    "        self.decode3 = Decoder(256, 256+128, 256)\n",
    "        self.decode2 = Decoder(256, 128+64, 128)\n",
    "        self.decode1 = Decoder(128, 64+64, 64)\n",
    "        self.decode0 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False)\n",
    "            )\n",
    "        self.conv_last = nn.Conv2d(64, self.n_class, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        e1 = self.layer1(input) # 64,256,256\n",
    "        e2 = self.layer2(e1) # 64,128,128\n",
    "        e3 = self.layer3(e2) # 128,64,64\n",
    "        e4 = self.layer4(e3) # 256,32,32\n",
    "        f = self.layer5(e4) # 512,16,16\n",
    "        d4 = self.decode4(f, e4) # 256,32,32\n",
    "        d3 = self.decode3(d4, e3) # 256,64,64\n",
    "        d2 = self.decode2(d3, e2) # 128,128,128\n",
    "        d1 = self.decode1(d2, e1) # 64,256,256\n",
    "        d0 = self.decode0(d1) # 64,512,512\n",
    "        out = self.conv_last(d0) # 1,512,512\n",
    "        \n",
    "        act = nn.Sigmoid()\n",
    "        return act(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LIDCDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LIDCDataset(imagestrain, maskstrain)\n",
    "val_dataset = LIDCDataset(imagestest, maskstest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评价指标\n",
    "\n",
    "# def dice_coef(y_pred, y_true, smooth=1e-5):\n",
    "#     multi = y_true * y_pred\n",
    "#     intersection = torch.sum(multi)\n",
    "#     multi = 0\n",
    "#     sumyt = torch.sum(y_true)\n",
    "#     sumyp = torch.sum(y_pred)\n",
    "#     union = sumyt + sumyp + smooth\n",
    "#     intersection = 2.0 * intersection + smooth\n",
    "#     dice = intersection.float() / union.float()\n",
    "#     return dice\n",
    "\n",
    "# def dice_loss(y_pred, y_true, smooth=1e-5):\n",
    "#     dice_loss = 1 - dice_coef(y_pred, y_true, smooth)\n",
    "#     return dice_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评价指标\n",
    "\n",
    "def dice_coef(pred, gt, smooth=1):\n",
    "\n",
    "    # N = gt.size(0)\n",
    "\n",
    "    pred_flat = pred.view(-1)\n",
    "    gt_flat = gt.view(-1)\n",
    "\n",
    "    intersection = pred_flat * gt_flat\n",
    "    \n",
    "    dice = (2 * intersection.sum() + smooth) / (pred_flat.sum() + gt_flat.sum() + smooth)\n",
    "    # dice = dice.sum() / N\n",
    "\n",
    "    return dice\n",
    "\n",
    "def dice_loss(pred, gt, smooth=1):\n",
    "    return 1 - dice_coef(pred, gt, smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "   \n",
    "max_lr = 0.0003\n",
    "min_lr = 0.0001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.#0001\n",
    "save_weight = weightsfolder + '/'\n",
    "weight_name = 'unet'\n",
    "num_epochs = 300\n",
    "scheduler_step = num_epochs // 10\n",
    "\n",
    "model = UNet()\n",
    "model = model.cuda()  # Move model to GPU if available\n",
    "\n",
    "# Define the optimizer and the scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
    "# Setup optimizer\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "# Setup scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_accuracy': [],\n",
    "    'val_accuracy': []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)  # Enable anomaly detection\n",
    "\n",
    "num_snapshot = 0\n",
    "best_param = []\n",
    "best_val_loss, best_loss = float('inf'), float('inf')  # Initialize best loss as infinity\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    print('Training...')\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()  # Move inputs and labels to GPU if available\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = dice_loss(outputs, labels)\n",
    "        accuracy = dice_coef(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.requires_grad_(True) #启用梯度计算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    print('Validating...')\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()  # Move inputs and labels to GPU if available\n",
    "\n",
    "            outputs = model.forward(inputs)\n",
    "            val_loss = dice_loss(outputs, labels)\n",
    "            val_accuracy = dice_coef(outputs, labels)\n",
    "\n",
    "    print(f'Done.\\nTraining Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}\\nTraining Accuracy: {accuracy.item():.4f}, Validation Accuracy: {val_accuracy.item():.4f}')\n",
    "    \n",
    "    lr_scheduler.step()  # Update learning rate\n",
    "    print(f'Learning rate is updated to {lr_scheduler.get_last_lr()}')\n",
    "    \n",
    "    # Save the model if validation loss is improved\n",
    "    if val_loss < best_val_loss and loss < best_loss:\n",
    "        print(f'Validation loss decreased from {best_val_loss} to {val_loss}.')\n",
    "        print(f'Training loss decreased from {best_loss} to {loss}.')\n",
    "        print('Update best parameters.\\n')\n",
    "        best_val_loss = val_loss\n",
    "        best_loss = loss\n",
    "        best_param = model.state_dict()\n",
    "        # torch.save(best_param, save_weight + weight_name + '_' + str(epoch) + '.pth')\n",
    "    \n",
    "    if (epoch + 1) % scheduler_step == 0:\n",
    "        print('Num_snapshot reached, Save the model and reset the optimizer.\\n')\n",
    "        torch.save(best_param, save_weight + weight_name + str(num_snapshot) + '.pth')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "        num_snapshot = num_snapshot + 1\n",
    "        best_val_loss = float('inf')\n",
    "        best_loss = float('inf')\n",
    "        best_param = []\n",
    "        \n",
    "    history['train_loss'].append(loss.item())\n",
    "    history['val_loss'].append(val_loss.item())\n",
    "    history['train_accuracy'].append(accuracy.item())\n",
    "    history['val_accuracy'].append(val_accuracy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制准确率曲线\n",
    "\n",
    "# plt.plot(history['dice_coef'], color='b')\n",
    "plt.plot(history['train_accuracy'], color='b')\n",
    "# plt.plot(history['val_dice_coef'], color='g')\n",
    "plt.plot(history['val_accuracy'], color='g')\n",
    "plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"accuracy\")\n",
    "plt.ylabel(\"dice_coef\")\n",
    "plt.legend([\"Train\", \"Test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存历史数据\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('history.pkl', 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "\n",
    "history['train_accuracy'][-1], history['val_accuracy'][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型\n",
    "\n",
    "best_param = torch.load(save_weight + weight_name + str(num_snapshot-1) + '.pth')\n",
    "model.load_state_dict(best_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = imagestest\n",
    "    labels = maskstest\n",
    "    outputs = model.forward(inputs)\n",
    "    loss = 1 - dice_coef(outputs, labels)\n",
    "    accuracy = dice_coef(outputs, labels)\n",
    "\n",
    "print(f\"Loss: {loss.item()}, Accuracy: {accuracy.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算模型的预测结果与测试数据的重叠率\n",
    "\n",
    "model.eval()\n",
    "num_test = imagestest.shape[0]\n",
    "imgs_mask_test = np.empty([num_test, 1, 512, 512], dtype=np.float32)\n",
    "for i in range(num_test):\n",
    "    inputs = imagestest[i:i+1].cuda()\n",
    "    outputs = model.forward(inputs)\n",
    "    imgs_mask_test[i] = outputs.cpu().detach().numpy()[0]\n",
    "\n",
    "sumoverlap = []\n",
    "for i in range(num_test):\n",
    "    sumoverlap.append(torch.sum(maskstest[i, 0] * imgs_mask_test[i, 0]).item())\n",
    "\n",
    "overlap_ratio = len([ov for ov in sumoverlap if ov > 1]) / len(sumoverlap)\n",
    "overlap_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制预测结果掩模及原始图像\n",
    "\n",
    "index=5\n",
    "print(\"Predicted\")\n",
    "plt.imshow(imgs_mask_test[index,0], cmap=\"gray\")\n",
    "plt.show()\n",
    "print(\"Ground Truth\")\n",
    "plt.imshow(maskstest[index,0],cmap=\"gray\")\n",
    "plt.show()\n",
    "print(\"Image\")\n",
    "plt.imshow(imagestest[index,0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
