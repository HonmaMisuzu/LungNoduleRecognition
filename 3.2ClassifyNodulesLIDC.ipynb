{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# 训练\n",
    "###############################\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 使用cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "print(device)\n",
    "\n",
    "truenoduleweightspath=\"modelpths/truenodule-cnn.pth\"                # 真假阳性分类模型的权重文件\n",
    "datafolder=\"processeddata\"                                          # 第一步预处理后的数据存放文件夹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "\n",
    "noduleimages=np.load(datafolder+\"/noduleimagesCNN.npy\")\n",
    "nodulelabels=np.load(datafolder+\"/nodulelabelsCNN.npy\")\n",
    "\n",
    "# with open(datafolder+\"/nodulesensitivity.pkl\", 'rb') as f:\n",
    "#     nodulesensitivity = pickle.load(f)\n",
    "with open(datafolder+\"/slicecountsCNN.pkl\", 'rb') as f:\n",
    "    slicecounts = pickle.load(f)\n",
    "\n",
    "noduleimages[noduleimages==-0]=0\n",
    "# nodulelabels[nodulelabels<=0]=0\n",
    "# nodulelabels[nodulelabels>0]=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假阳性样本序号列表\n",
    "\n",
    "falseind = [i for i in range(len(nodulelabels)) if nodulelabels[i] == False]\n",
    "random.shuffle(falseind)\n",
    "falseind = falseind[:noduleimages.shape[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算TP和FP\n",
    "\n",
    "TP=len([nl for nl in nodulelabels if nl==True])\n",
    "FP=len([nl for nl in nodulelabels if nl==False])\n",
    "print(\"Number of True Positive nodules:\",TP)\n",
    "print(\"Number of False Positive nodules:\",FP)\n",
    "print(\"# of FPs per TP\",FP/TP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平衡数据集\n",
    "\n",
    "# 从FP中随机选择与TP数量相同的样本\n",
    "random.seed()\n",
    "FPindices=random.sample([i for i in range(len(nodulelabels)) if nodulelabels[i]==False],TP)\n",
    "noduleimages=noduleimages[[i for i in range(len(nodulelabels)) if nodulelabels[i]==True]+FPindices]\n",
    "nodulelabels=nodulelabels[[i for i in range(len(nodulelabels)) if nodulelabels[i]==True]+FPindices]\n",
    "print(\"Number of True Positive nodules:\",len([nl for nl in nodulelabels if nl==True]))\n",
    "print(\"Number of False Positive nodules:\",len([nl for nl in nodulelabels if nl==False]))\n",
    "print(\"# of FPs per TP\",len([nl for nl in nodulelabels if nl==False])/len([nl for nl in nodulelabels if nl==True]))\n",
    "\n",
    "noduleimages = torch.from_numpy(noduleimages).float()\n",
    "nodulelabels = F.one_hot(torch.from_numpy(nodulelabels).long(), 2).float()\n",
    "\n",
    "print(nodulelabels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(noduleimages, nodulelabels, test_size=0.3, random_state=114)\n",
    "\n",
    "del noduleimages, nodulelabels\n",
    "\n",
    "# 定义数据集类\n",
    "\n",
    "class NoduleDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return (image, label)\n",
    "    \n",
    "# Create instances of the dataset\n",
    "train_dataset = NoduleDataset(X_train, y_train)\n",
    "test_dataset = NoduleDataset(X_test, y_test)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类结节与非结节\n",
    "\n",
    "# 定义模型\n",
    "from TrueNoduleClassifier import NoduleClassifier\n",
    "\n",
    "# Create an instance of the model\n",
    "model = NoduleClassifier().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_accuracy': [],\n",
    "    'val_accuracy': []\n",
    "}\n",
    "\n",
    "# best_val_loss = float('inf')\n",
    "# best_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "best_accuracy = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}:')\n",
    "    model.train()\n",
    "    total_samples = 0\n",
    "    total_correct = 0\n",
    "    train_loss = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "        # train_accuracy = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "        total_correct = total_correct + (predicted == labels[:,1]).sum().item()\n",
    "        total_samples = total_samples + (predicted.size(0))\n",
    "        loss.requires_grad_(True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss = train_loss / len(train_loader)\n",
    "    train_accuracy = total_correct / total_samples\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in tqdm(test_loader):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "            total_correct = total_correct + (predicted == labels[:,1]).sum().item()\n",
    "            total_samples = total_samples + (predicted.size(0))\n",
    "\n",
    "        val_loss = total_val_loss / len(test_loader)\n",
    "        val_accuracy = total_correct / total_samples\n",
    "        print(f'Training loss: {loss:.4f},   Training accuracy: {train_accuracy:.4f}\\n'\n",
    "              f'Validation loss: {val_loss:.4f}, Validation accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Save the model if validation loss is improved\n",
    "    if loss < best_loss:\n",
    "        print(f'Train loss decreased from {best_loss} to {loss}.')\n",
    "        print('Update best parameters, and save weights.')\n",
    "        best_loss = loss\n",
    "        best_param = model.state_dict()\n",
    "        torch.save(model.state_dict(), truenoduleweightspath)\n",
    "\n",
    "    history['train_loss'].append(loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_accuracy'].append(train_accuracy)\n",
    "    history['val_accuracy'].append(val_accuracy)\n",
    "# 36min 42.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(history['train_accuracy'])):\n",
    "    try:\n",
    "        history['train_accuracy'][i] = history['train_accuracy'][i].item()\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history['train_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('historyTPCNN.pkl', 'wb') as f:\n",
    "    pickle.dump(history, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制损失和准确率变化折线图\n",
    "\n",
    "plt.plot(history['train_loss'], color='b')\n",
    "plt.plot(history['val_loss'], color='g')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "plt.show()\n",
    "plt.plot(history['train_accuracy'], color='b') #acc\n",
    "plt.plot(history['val_accuracy'], color='g')  #val_acc\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将测试数据集分为只有真结节或非结节的两类\n",
    "\n",
    "XtestTrue_tensor = X_test[y_test[:,1]==1]\n",
    "YtestTrue_tensor = y_test[y_test[:,1]==1]\n",
    "\n",
    "XtestFalse_tensor = X_test[y_test[:,1]==0]\n",
    "YtestFalse_tensor = y_test[y_test[:,1]==0]\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立数据加载器\n",
    "\n",
    "XtestTrue_loader = DataLoader(NoduleDataset(XtestTrue_tensor, YtestTrue_tensor), batch_size=32, shuffle=False)\n",
    "XtestFalse_loader = DataLoader(NoduleDataset(XtestFalse_tensor, YtestFalse_tensor), batch_size=32, shuffle=False)\n",
    "\n",
    "# 加载模型\n",
    "\n",
    "model.load_state_dict(torch.load(truenoduleweightspath))\n",
    "model.eval()\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "correct_true = 0\n",
    "total_true = 0\n",
    "correct_false = 0\n",
    "total_false = 0\n",
    "loss_true = 0\n",
    "loss_false = 0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "predlabels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(XtestTrue_loader):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        predlabels.extend(predicted.cpu().numpy())\n",
    "        total_true += predicted.size(0)\n",
    "        correct_true += (predicted == labels[:,1].long()).sum().item()\n",
    "        loss_true += criterion(outputs, labels).item()\n",
    "\n",
    "    for inputs, labels in tqdm(XtestFalse_loader):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        predlabels.extend(predicted.cpu().numpy())\n",
    "        total_false += predicted.size(0)\n",
    "        correct_false += (predicted == labels[:,1].long()).sum().item()\n",
    "        loss_false += criterion(outputs, labels).item()\n",
    "\n",
    "accuracy_true = correct_true / total_true\n",
    "accuracy_false = correct_false / total_false\n",
    "\n",
    "print(f'Accuracy for True nodules: {accuracy_true:.4f}')\n",
    "print(f'Accuracy for False nodules: {accuracy_false:.4f}')\n",
    "\n",
    "loss_true /= len(XtestTrue_loader)\n",
    "loss_false /= len(XtestFalse_loader)\n",
    "\n",
    "print(f'Loss for True nodules: {loss_true:.4f}')\n",
    "print(f'Loss for False nodules: {loss_false:.4f}')\n",
    "\n",
    "score_true = {'loss': loss_true, 'accuracy': accuracy_true}\n",
    "score_false = {'loss': loss_false, 'accuracy': accuracy_false}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Sensitivity:\", 0.7716) # Evaluated from 2TrainUnet.ipynb\n",
    "print(\"FP Rate/slice:\", len(falseind)/(sum(slicecounts))) # +slicecounts2\n",
    "print(\"FP Rate/slice after nodule classification:\", len(falseind)*(1-score_false['accuracy'])/(sum(slicecounts))) # +slicecounts2\n",
    "print(\"Sensitivity after nodule classification:\", 0.7716*score_true['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predlabels = np.array(predlabels)\n",
    "TP=len([nl for nl in predlabels if nl==True])\n",
    "FP=len([nl for nl in predlabels if nl==False])\n",
    "print(\"Number of True Positive nodules:\",TP)\n",
    "print(\"Number of False Positive nodules:\",FP)\n",
    "print(\"# of FPs per TP\",FP/TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch221",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
