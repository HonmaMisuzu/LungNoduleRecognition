{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 测试用的程序\n",
    "########################################\n",
    "\n",
    "# 下面是从DetectNodules.ipynb获取到的结节图像、掩码数据及其特征表的路径\n",
    "DATAFOLDER = 'F:\\\\Datasets\\\\DSB3-processed\\\\'\n",
    "imageslist=[f'{DATAFOLDER}DSBNoduleImages.npy']\n",
    "maskslist=[f'{DATAFOLDER}DSBNoduleMasks.npy']\n",
    "tablelist=[f'{DATAFOLDER}DSBNoduleFeatures.csv']\n",
    "\n",
    "########################################\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "# 尝试使用可扩展的内存段来避免CUDA内存碎片化\n",
    "# 请注意，这可能会导致性能下降，因为这会导致更多的内存分配和释放操作\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# 使用cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取每个图像的最大结节，对处理过的图像进行64x64的裁剪，并用良恶性标签进行标记。\n",
    "from ProcessCTData import processimagenomask, crop_nodule, largestnodulearea, largestnodulecoordinates\n",
    "\n",
    "table = pd.read_csv(tablelist[0])\n",
    "if len(tablelist) > 1:\n",
    "    for file in tablelist[1:]:\n",
    "        temptable = pd.read_csv(file)\n",
    "        table = pd.concat([table, temptable])\n",
    "table = table.reset_index()\n",
    "\n",
    "print(\"Top 10 of DSBNoduleFeatures.csv :\\n\", table[:10])\n",
    "\n",
    "malignantlabel = []\n",
    "malignancytable = pd.concat([pd.read_csv(\"DSB/stage1_labels.csv\"), \n",
    "                             pd.read_csv(\"DSB/stage1_solution.csv\")])\n",
    "patients = malignancytable[\"id\"].values\n",
    "index = 0\n",
    "noduleexists = []\n",
    "nodulecrops = np.ndarray([len(patients), 1, 64, 64])\n",
    "indicies = []\n",
    "\n",
    "for i in range(len(imageslist)):\n",
    "    print(\"loading file\", imageslist[i])\n",
    "    noduleimages = np.load(imageslist[i])\n",
    "    nodulemasks = np.load(maskslist[i])\n",
    "    tabletemp = pd.read_csv(tablelist[i])\n",
    "    biggestnodulearea = []\n",
    "\n",
    "    for j in range(nodulemasks.shape[0]):\n",
    "        biggestnodulearea.append(largestnodulearea(nodulemasks[j, 0], tabletemp, j))\n",
    "\n",
    "    tabletemp[\"LargestNoduleArea\"] = pd.Series(biggestnodulearea)\n",
    "\n",
    "    for patient in tqdm(patients):\n",
    "        print(\"Process patient \", patient)\n",
    "        nodulearea = tabletemp[[\"LargestNoduleArea\"]].loc[tabletemp[\"Patient\"] == patient]\n",
    "\n",
    "        if len(nodulearea) > 0:\n",
    "            malignantlabel.append(malignancytable[\"cancer\"].loc[malignancytable[\"id\"] == patient].values[0].astype(bool))\n",
    "            noduleexists.append(1)\n",
    "            indx = nodulearea.loc[nodulearea[\"LargestNoduleArea\"] == max(nodulearea[\"LargestNoduleArea\"])].index[0]\n",
    "            indicies.append(indx)\n",
    "            nodcrop = crop_nodule(largestnodulecoordinates(nodulemasks[indx, 0]), processimagenomask(noduleimages[indx, 0]))\n",
    "\n",
    "            if nodcrop.shape[0] * nodcrop.shape[1] < 64 ** 2:\n",
    "                nodulecrops[index, 0] = np.zeros([64, 64])\n",
    "                nodulecrops[index, 0][0:nodcrop.shape[0], 0:nodcrop.shape[1]] = nodcrop\n",
    "            else:\n",
    "                nodulecrops[index, 0] = nodcrop\n",
    "\n",
    "            index += 1\n",
    "\n",
    "nodulecrops = nodulecrops[:index]\n",
    "# nodulecrops = nodulecrops.reshape(nodulecrops.shape[0], 64, 64, 1)\n",
    "# features = table.iloc[indicies]\n",
    "# features[\"label\"] = malignantlabel\n",
    "TFratio = len([a for a in malignantlabel if a == True]) / len(malignantlabel)\n",
    "print(\"Percent labels True: \", TFratio)\n",
    "\n",
    "malignantlabel = np.array(malignantlabel, dtype=bool)\n",
    "\n",
    "print(\"Number of nodules: \", len(nodulecrops))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示结节图像\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 4))\n",
    "\n",
    "for i, j in enumerate((10, 22, 46, 60)):\n",
    "    ax[i].imshow(nodulecrops[j, 0])\n",
    "    ax[i].axis(\"off\")\n",
    "    ax[i].set_title(\"Malignant: \" + str(malignantlabel[j]))\n",
    "# for i in range(5):\n",
    "#     ax[i].imshow(nodulecrops[i, 0])\n",
    "#     ax[i].axis(\"off\")\n",
    "#     ax[i].set_title(\"Malignant: \" + str(malignantlabel[i]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据集类\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class NoduleDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "nodulecrops = torch.from_numpy(nodulecrops).float()\n",
    "malignantlabel = F.one_hot(torch.from_numpy(malignantlabel).long(), 2).float()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(nodulecrops, malignantlabel, test_size=0.3)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "train_dataset = NoduleDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_dataset = NoduleDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "\n",
    "from NoduleCancerClassifier import CNNModel\n",
    "\n",
    "model = CNNModel(2, 32).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "modelpath = \"modelpths/NoduleCancerClassifier.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "\n",
    "history = []\n",
    "epochs = 200\n",
    "\n",
    "# Train the model\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "\n",
    "# Initialize the best validation loss\n",
    "best_train_loss = np.inf\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.requires_grad_(True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        train_correct += (predicted_labels == labels[:,1]).sum().item()\n",
    "        total += predicted_labels.size(0)\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = train_correct / total\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_history.append(train_accuracy)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            test_correct += (predicted_labels == labels[:,1]).sum().item()\n",
    "            total += predicted_labels.size(0)\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = test_correct / total\n",
    "    test_loss_history.append(test_loss)\n",
    "    test_acc_history.append(test_accuracy)\n",
    "\n",
    "    # print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.4f}')\n",
    "    if train_loss < best_train_loss:\n",
    "        print(f'Epoch {epoch + 1}/{epochs}')\n",
    "        print(f'Train_loss decrease from {best_train_loss:.4f} to {train_loss:.4f}. Saving model...')\n",
    "        best_train_loss = train_loss\n",
    "        torch.save(model.state_dict(), modelpath)\n",
    "history.append({\n",
    "    'train_loss': train_loss_history,\n",
    "    'train_acc': train_acc_history,\n",
    "    'test_loss': test_loss_history,\n",
    "    'test_acc': test_acc_history\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估模型效果\n",
    "\n",
    "predicted = []\n",
    "malignantlabeltest = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(nodulecrops.cuda())\n",
    "    _, predicted_labels = torch.max(outputs, 1)\n",
    "    val_loss = criterion(outputs, malignantlabel.cuda()).item()\n",
    "    val_accuracy = (predicted_labels.cpu() == malignantlabel[:,1]).sum().item() / len(malignantlabel[:,1])\n",
    "    predicted.append(outputs[:, 1].cpu().numpy())\n",
    "    malignantlabeltest.append(malignantlabel[:,1])\n",
    "\n",
    "predicted = np.concatenate(predicted, axis=0)\n",
    "malignantlabeltest = np.concatenate(malignantlabeltest, axis=0)\n",
    "\n",
    "roc = roc_curve(malignantlabeltest, predicted)\n",
    "auc = roc_auc_score(malignantlabeltest, predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出评估结果\n",
    "print(\"Lowest train_loss of\", min(history[0]['train_loss']), \"at epoch\", np.argmin(history[0]['train_loss']))\n",
    "print(\"Lowest test_loss of\", min(history[0]['test_loss']), \"at epoch\", np.argmin(history[0]['test_loss']))\n",
    "print(\"Highest train_acc of\", max(history[0]['train_acc']), \"at epoch\", np.argmax(history[0]['train_acc']))\n",
    "print(\"Highest test_acc of\", max(history[0]['test_acc']), \"at epoch\", np.argmax(history[0]['test_acc']))\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# 绘制训练和测试损失曲线\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(train_loss_history, label=\"Train Loss\")\n",
    "plt.plot(test_loss_history, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 绘制训练和测试准确率曲线\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(train_acc_history, label=\"Train Accuracy\")\n",
    "plt.plot(test_acc_history, label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 绘制ROC曲线\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(roc[0], roc[1])\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(f\"ROC Curve (AUC={auc:.4f})\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch221",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
