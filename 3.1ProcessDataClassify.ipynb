{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# 准备肺结节真假阳性分类模型的数据\n",
    "###############################\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom as dicom\n",
    "import os\n",
    "import scipy.ndimage\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage import measure, morphology\n",
    "import cell_magic_wand as cmw\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "list32file=\"LIDC/list3.2.csv\"\n",
    "metafile=\"LIDC/LIDC-IDRI_MetaData.csv\"\n",
    "unetweightspath=\"modelpths/unet9.pth\"                               # U-net模型的权重文件 \n",
    "datafolder=\"processeddata\"                                          # 第一步预处理后的数据存放文件夹\n",
    "Datapath='H:/Datasets/LIDC-IDRI/manifest-1600709154662/LIDC-IDRI/'  # LIDC数据集路径\n",
    "\n",
    "nodulelocations=pd.read_csv(list32file)\n",
    "meta=pd.read_csv(metafile)\n",
    "\n",
    "meta=meta.drop(meta[meta['Modality']!='CT'].index)\n",
    "meta=meta.reset_index()\n",
    "\n",
    "#Get folder names of CT data for each patient\n",
    "patients=[Datapath+meta['Patient Id'][i] for i in range(len(meta))]\n",
    "datfolder=[]\n",
    "for i in range(0,len(meta)-1):\n",
    "    for path in os.listdir(patients[i]):\n",
    "        if os.path.exists(patients[i]+'/'+path+'/'+meta['Series UID'][i]):\n",
    "            datfolder.append(patients[i]+'/'+path+'/'+meta['Series UID'][i])\n",
    "patients=datfolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型\n",
    "from NoduleUNet import UNet\n",
    "\n",
    "model = UNet().to(device)\n",
    "model.load_state_dict(torch.load(unetweightspath))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scans in given folder path\n",
    "# code sourced from https://www.kaggle.com/gzuidhof/full-preprocessing-tutorial\n",
    "def load_scan(path):\n",
    "    slices = [dicom.read_file(path + '/' + s, force=True) for s in os.listdir(path) if s.endswith('.dcm')]\n",
    "    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]), reverse=True)\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        \n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "        \n",
    "    return slices\n",
    "\n",
    "#convert to ndarray\n",
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "def processimage(img):\n",
    "    #function sourced from https://www.kaggle.com/c/data-science-bowl-2017#tutorial\n",
    "    #Standardize the pixel values\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img = img-mean\n",
    "    img = img/std\n",
    "    #plt.hist(img.flatten(),bins=200)\n",
    "    #plt.show()\n",
    "    #print(thresh_img[366][280:450])\n",
    "    middle = img[100:400,100:400] \n",
    "    mean = np.mean(middle) \n",
    "    max = np.max(img)\n",
    "    min = np.min(img)\n",
    "    #move the underflow bins\n",
    "    img[img==max]=mean\n",
    "    img[img==min]=mean\n",
    "    kmeans = KMeans(n_clusters=2).fit(np.reshape(middle,[np.prod(middle.shape),1]))\n",
    "    del middle, mean, max, min\n",
    "\n",
    "    centers = sorted(kmeans.cluster_centers_.flatten())\n",
    "    threshold = np.mean(centers)\n",
    "    del centers, kmeans\n",
    "\n",
    "    thresh_img = np.where(img<threshold,1.0,0.0)  # threshold the image\n",
    "    eroded = morphology.erosion(thresh_img,np.ones([4,4]))\n",
    "    dilation = morphology.dilation(eroded,np.ones([10,10]))\n",
    "    del thresh_img, eroded\n",
    "\n",
    "    labels = measure.label(dilation)\n",
    "    del dilation\n",
    "\n",
    "    #plt.imshow(labels)\n",
    "    #plt.show()\n",
    "    regions = measure.regionprops(labels)\n",
    "    good_labels = []\n",
    "    for prop in regions:\n",
    "        B = prop.bbox\n",
    "        if B[2]-B[0]<475 and B[3]-B[1]<475 and B[0]>40 and B[2]<472:\n",
    "            good_labels.append(prop.label)\n",
    "    del regions\n",
    "\n",
    "    mask = np.ndarray([512,512],dtype=np.int8)\n",
    "    mask[:] = 0\n",
    "    #\n",
    "    #  The mask here is the mask for the lungs--not the nodes\n",
    "    #  After just the lungs are left, we do another large dilation\n",
    "    #  in order to fill in and out the lung mask \n",
    "    #\n",
    "    for N in good_labels:\n",
    "        mask = mask + np.where(labels==N,1,0)\n",
    "    del labels, good_labels\n",
    "\n",
    "    mask = morphology.dilation(mask,np.ones([10,10])) # one last dilation\n",
    "    return mask*img\n",
    "\n",
    "def processimagefromfile(ppix):\n",
    "    processpix=np.ndarray([ppix.shape[0],512,512])\n",
    "    for i in range(ppix.shape[0]):\n",
    "        processpix[i]=processimage(ppix[i])\n",
    "    return processpix\n",
    "\n",
    "#predict mask from images\n",
    "def predictmask(images):\n",
    "    images=images.reshape(images.shape[0],1,512,512)\n",
    "    num_test=images.shape[0]\n",
    "    imgs_mask_test = np.ndarray([num_test,1,512,512],dtype=np.float32)\n",
    "    for i in range(num_test):\n",
    "        imgs_mask_test[i] = model.forward(torch.from_numpy(images[i:i+1]).to(device).float()).cpu().detach().numpy()[0]\n",
    "    return imgs_mask_test\n",
    "\n",
    "#find number of slices where a nodule is detected\n",
    "def getnoduleindex(imgs_mask_test):\n",
    "    masksum=[np.sum(maskslice[0]) for maskslice in imgs_mask_test]\n",
    "    return [i for i in range(len(masksum)) if masksum[i]>5]\n",
    "\n",
    "def nodule_coordinates(nodulelocations,meta):\n",
    "    slices=nodulelocations[\"slice no.\"][nodulelocations.index[nodulelocations[\"case\"]==int(meta[\"Patient Id\"][-4:])]]\n",
    "    xlocs=nodulelocations[\"x loc.\"][nodulelocations.index[nodulelocations[\"case\"]==int(meta[\"Patient Id\"][-4:])]]\n",
    "    ylocs=nodulelocations[\"y loc.\"][nodulelocations.index[nodulelocations[\"case\"]==int(meta[\"Patient Id\"][-4:])]]\n",
    "    nodulecoord=[]\n",
    "    for i in range(len(slices)):\n",
    "        nodulecoord.append([slices.values[i]-1,xlocs.values[i]-1,ylocs.values[i]-1])\n",
    "    return nodulecoord\n",
    "\n",
    "#generate nodule or non-nodule labels for mask predictions\n",
    "def truenodules(noduleindex,masks,nodulecoords):\n",
    "    label=[]\n",
    "    for ind in noduleindex:\n",
    "        for cord in nodulecoords:\n",
    "            if abs(ind-cord[0])<2:\n",
    "                com=scipy.ndimage.center_of_mass(masks[ind])\n",
    "                if abs(com[1]-cord[2])<2 and abs(com[2]-cord[1])<2:\n",
    "                    label.append(True)\n",
    "            else:\n",
    "                label.append(False)\n",
    "    return label\n",
    "\n",
    "# def slicecount(start,end):\n",
    "#     slicecounts=[]\n",
    "#     for i in range(start,end):\n",
    "#         if len(nodule_coordinates(nodulelocations,meta.iloc[i]))>0:\n",
    "#             patient_scan=load_scan(patients[i])\n",
    "#             slicecounts.append(len(patient_scan))\n",
    "#     return slicecounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicecounts=[]\n",
    "\n",
    "for i in range(len(patients)):\n",
    "    if len(nodule_coordinates(nodulelocations, meta.iloc[i]))>0:\n",
    "        patient_scan=load_scan(patients[i])\n",
    "        slicecounts.append(len(patient_scan))\n",
    "\n",
    "import pickle\n",
    "with open(datafolder+\"/slicecountsCNN.pkl\", 'wb') as f:\n",
    "    pickle.dump(slicecounts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 获得TP与FP标签\n",
    "\n",
    "def get_nodule_label(i):\n",
    "    nodulelabels=[]\n",
    "    nodulesensitivity=[]\n",
    "    slicecounts=[]\n",
    "    noduleimages = []\n",
    "    print(\"Processing patient#\",i)\n",
    "    if len(nodule_coordinates(nodulelocations, meta.iloc[i]))>0:\n",
    "        patient_scan=load_scan(patients[i])\n",
    "        slicecounts.append(len(patient_scan))\n",
    "        patient_pix=get_pixels_hu(patient_scan)\n",
    "        del patient_scan\n",
    "        processed_pix = processimagefromfile(patient_pix)\n",
    "        coord = nodule_coordinates(nodulelocations,meta.iloc[i])\n",
    "        print(coord)\n",
    "        radius = nodulelocations[\"eq. diam.\"][nodulelocations.index[nodulelocations[\"case\"]==int(meta[\"Patient Id\"][i][-4:])]]\n",
    "        print(radius)\n",
    "        mask = predictmask(processed_pix)\n",
    "        noduleindex = getnoduleindex(mask)        \n",
    "        labels = np.zeros(len(noduleindex)).astype(bool)\n",
    "        cordlabels=np.zeros(len(coord)).astype(bool)\n",
    "        for j,cord in enumerate(coord): # loop through labeled nodules\n",
    "            if radius.iloc[j]>5:\n",
    "                nodulemask = cmw.cell_magic_wand(-patient_pix[int(cord[0])],[int(cord[2]),int(cord[1])],2,int(radius.iloc[j])+2)\n",
    "                nodulepix=nodulemask*patient_pix[cord[0]]\n",
    "                nodulepix[nodulepix<-500]=0 #lower HU threshold for nodule segmentation\n",
    "                nodulepix[nodulepix!=0]=1\n",
    "                nodulemask=nodulepix.astype(bool)\n",
    "                del nodulepix\n",
    "                for k,ind in enumerate(noduleindex): # loop through detected nodules\n",
    "                    if abs(ind-cord[0])<2:\n",
    "                        if np.sum(nodulemask*mask[ind][0])>1:\n",
    "                            print(\"Nodule Detected at slice#\",ind,\"with actual coord\",cord)\n",
    "                            labels[k] = True\n",
    "                            cordlabels[j] = True\n",
    "        del patient_pix, mask, radius\n",
    "        for j in range(len(coord)):\n",
    "            nodulesensitivity.append(cordlabels[j])\n",
    "        \n",
    "        nodulelabels.append(labels[[k for k in range(len(noduleindex))]])\n",
    "        noduleimages = processed_pix[[noduleindex[k] for k in range(len(noduleindex))]]\n",
    "\n",
    "    return noduleimages, nodulelabels, nodulesensitivity, slicecounts\n",
    "\n",
    "# 多线程处理，非常耗费内存和CPU\n",
    "\n",
    "MAX_WORKERS = 28 # 根据你的CPU核心数设置\n",
    "\n",
    "from tqdm.contrib.concurrent import thread_map\n",
    "results = thread_map(get_nodule_label, range(len(patients)), max_workers=MAX_WORKERS)\n",
    "\n",
    "# Save the results to corresponding variables\n",
    "noduleimages = []\n",
    "nodulelabels = []\n",
    "nodulesensitivity = []\n",
    "slicecounts = []\n",
    "\n",
    "for res in results:\n",
    "    if len(res[0]) > 0:\n",
    "        noduleimages.append(res[0])\n",
    "        nodulelabels.extend(res[1])\n",
    "        nodulesensitivity.extend(res[2])\n",
    "        slicecounts.extend(res[3])\n",
    "\n",
    "del results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理数据\n",
    "\n",
    "nodulelabels = [item for sublist in nodulelabels for item in sublist]\n",
    "nodulelabels = [item for sublist in nodulelabels for item in sublist]\n",
    "\n",
    "noduleimages=np.concatenate(noduleimages)\n",
    "\n",
    "noduleimages=noduleimages[:len(nodulelabels)]\n",
    "noduleimages=noduleimages.reshape([noduleimages.shape[0],1,512,512])\n",
    "nodulelabels=np.array(nodulelabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "\n",
    "np.save(datafolder+\"/noduleimagesCNN.npy\",noduleimages)\n",
    "np.save(datafolder+\"/nodulelabelsCNN.npy\",nodulelabels)\n",
    "\n",
    "import pickle\n",
    "with open(datafolder+\"/nodulesensitivityCNN.pkl\", 'wb') as f:\n",
    "    pickle.dump(nodulesensitivity, f)\n",
    "with open(datafolder+\"/slicecountsCNN.pkl\", 'wb') as f:\n",
    "    pickle.dump(slicecounts, f)\n",
    "\n",
    "del noduleimages, nodulelabels, nodulesensitivity, slicecounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
